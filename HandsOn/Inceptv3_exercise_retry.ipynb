{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "width = 299\n",
    "height = 299\n",
    "channels = 3\n",
    "\n",
    "import sys\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "import os\n",
    "\n",
    "print(\"Point 1 elapsed time is {:.2f}s\".format(time.time()-start_time))\n",
    "\n",
    "TF_MODELS_URL = \"http://download.tensorflow.org/models\"\n",
    "INCEPTION_V3_URL = TF_MODELS_URL + \"/inception_v3_2016_08_28.tar.gz\"\n",
    "INCEPTION_PATH = os.path.join(\"datasets\", \"inception\")\n",
    "INCEPTION_V3_CHECKPOINT_PATH = os.path.join(INCEPTION_PATH, \"inception_v3.ckpt\")\n",
    "\n",
    "def download_progress(count, block_size, total_size):\n",
    "    percent = count * block_size * 100 // total_size\n",
    "    sys.stdout.write(\"\\rDownloading: {}%\".format(percent))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def fetch_pretrained_inception_v3(url=INCEPTION_V3_URL, path=INCEPTION_PATH):\n",
    "    if os.path.exists(INCEPTION_V3_CHECKPOINT_PATH):\n",
    "        return\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    tgz_path = os.path.join(path, \"inception_v3.tgz\")\n",
    "    urllib.request.urlretrieve(url, tgz_path, reporthook=download_progress)\n",
    "    inception_tgz = tarfile.open(tgz_path)\n",
    "    inception_tgz.extractall(path=path)\n",
    "    inception_tgz.close()\n",
    "    os.remove(tgz_path)\n",
    "\n",
    "fetch_pretrained_inception_v3()\n",
    "\n",
    "print(\"Point 2 elapsed time is {:.2f}s\".format(time.time()-start_time))\n",
    "\n",
    "import re\n",
    "\n",
    "CLASS_NAME_REGEX = re.compile(r\"^n\\d+\\s+(.*)\\s*$\", re.M|re.U)\n",
    "\n",
    "def load_class_names():\n",
    "    with open(os.path.join(\"datasets\", \"inception\", \"imagenet_class_names.txt\"),\"rb\") as f:\n",
    "        countent = f.read().decode(\"utf-8\")\n",
    "        return CLASS_NAME_REGEX.findall(countent)\n",
    "\n",
    "class_names = load_class_names()\n",
    "\n",
    "class_names[:5]\n",
    "\n",
    "print(\"Point 3 elapsed time is {:.2f}s\".format(time.time()-start_time))\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_image = mpimg.imread(os.path.join(\"images\", \"cnn\", \"Alaskan_Malamute.jpg\"))[:,:,:channels]\n",
    "#plt.imshow(test_image)\n",
    "#plt.axis(\"off\")\n",
    "#plt.show()\n",
    "test_image = prepare_image(test_image)\n",
    "\n",
    "X_test = test_image.reshape(-1, height, width, channels)\n",
    "\n",
    "print(\"Point 4 elapsed time is {:.2f}s\".format(time.time()-start_time))\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Point 5 elapsed time is {:.2f}s\".format(time.time()-start_time))\n",
    "\n",
    "from tensorflow.contrib.slim.nets import inception\n",
    "print(\"Point 6 elapsed time is {:.2f}s\".format(time.time()-start_time))\n",
    "\n",
    "import tensorflow.contrib.slim as slim\n",
    "print(\"Point 7 elapsed time is {:.2f}s\".format(time.time()-start_time))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 299, 299, 3], name=\"X\")\n",
    "with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "    print(\"Point 7.1 elapsed time is {:.2f}s\".format(time.time()-start_time))    \n",
    "    logits, end_points = inception.inception_v3(X, num_classes=1001, is_training = False)\n",
    "print(\"Point 7.2 elapsed time is {:.2f}s\".format(time.time()-start_time))\n",
    "predictions = end_points[\"Predictions\"]\n",
    "print(\"Point 7.3 elapsed time is {:.2f}s\".format(time.time()-start_time))\n",
    "\n",
    "probabilities = tf.nn.softmax(logits)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "print(\"Point 8 elapsed time is {:.2f}s\".format(time.time()-start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, INCEPTION_V3_CHECKPOINT_PATH)\n",
    "    print(\"Point 9 elapsed time is {:.2f}s\".format(time.time()-start_time))\n",
    "\n",
    "    predictions_val = predictions.eval(feed_dict={X: X_test})\n",
    "    print(\"Point 10 elapsed time is {:.2f}s\".format(time.time()-start_time))\n",
    "    \n",
    "    bb_val = probabilities.eval (feed_dict={X: X_test})\n",
    "\n",
    "most_likely_class_index = np.argmax(predictions_val[0])\n",
    "print(most_likely_class_index)\n",
    "\n",
    "print(class_names[most_likely_class_index])\n",
    "\n",
    "top_5 = np.argpartition(predictions_val[0], -5)[-5:]\n",
    "top_5 = top_5[np.argsort(predictions_val[0][top_5])]\n",
    "\n",
    "print(\"Point 11 elapsed time is {:.2f}s\".format(time.time()-start_time))\n",
    "for i in top_5:\n",
    "    print(\"{0}: {1:.2f}%\".format(class_names[i], 100 * predictions_val[0][i]))\n",
    "\n",
    "print(\"Point 12 elapsed time is {:.2f}s\".format(time.time()-start_time))    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append(r\"/Users/yiwenliu/Desktop/Projects/PML/HandsOn/models/slim/preprocessing\")\n",
    "import inception_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from preprocessing import inception_preprocessing\n",
    "session = tf.Session()\n",
    "\n",
    "image_size = inception.inception_v3.default_image_size\n",
    "def transform_img_fn(path_list):\n",
    "    out = []\n",
    "    for f in path_list:\n",
    "        a = open(f, 'rb').read()\n",
    "        image_raw = tf.image.decode_jpeg(open(f, 'rb').read(), channels=3)\n",
    "        print(\"type is {}\".format(image_raw.dtype))\n",
    "#        image = inception_preprocessing.preprocess_image(image_raw, image_size, image_size, is_training=False)\n",
    "        image = preprocess_for_eval(image_raw, image_size, image_size)\n",
    "        out.append(image)\n",
    "    return session.run([out])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = transform_img_fn(['images/cnn/cat.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_for_eval(image, height, width,\n",
    "                        central_fraction=0.875, scope=None):\n",
    "  \"\"\"Prepare one image for evaluation.\n",
    "  If height and width are specified it would output an image with that size by\n",
    "  applying resize_bilinear.\n",
    "  If central_fraction is specified it would crop the central fraction of the\n",
    "  input image.\n",
    "  Args:\n",
    "    image: 3-D Tensor of image. If dtype is tf.float32 then the range should be\n",
    "      [0, 1], otherwise it would converted to tf.float32 assuming that the range\n",
    "      is [0, MAX], where MAX is largest positive representable number for\n",
    "      int(8/16/32) data type (see `tf.image.convert_image_dtype` for details)\n",
    "    height: integer\n",
    "    width: integer\n",
    "    central_fraction: Optional Float, fraction of the image to crop.\n",
    "    scope: Optional scope for name_scope.\n",
    "  Returns:\n",
    "    3-D float Tensor of prepared image.\n",
    "  \"\"\"\n",
    "  with tf.name_scope(scope, 'eval_image', [image, height, width]):\n",
    "    if image.dtype != tf.float32:\n",
    "      image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    # Crop the central region of the image with an area containing 87.5% of\n",
    "    # the original image.\n",
    "    if central_fraction:\n",
    "      image = tf.image.central_crop(image, central_fraction=central_fraction)\n",
    "\n",
    "    if height and width:\n",
    "      # Resize the image to the specified height and width.\n",
    "      image = tf.expand_dims(image, 0)\n",
    "      image = tf.image.resize_bilinear(image, [height, width],\n",
    "                                       align_corners=False)\n",
    "      image = tf.squeeze(image, [0])\n",
    "      image = tf.subtract(image, 0.5)\n",
    "      image = tf.multiply(image, 2.0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.squeeze(predictions_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_val[0][172:176]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_val[0][726]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_image = mpimg.imread(os.path.join(\"images\", \"cnn\", \"test_image.jpeg\"), format=\"jpeg\")[:,:,:channels]\n",
    "#plt.imshow(test_image)\n",
    "#plt.axis(\"off\")\n",
    "#plt.show()\n",
    "X_test = test_image.reshape(-1, height, width, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = tf.image.convert_image_dtype(X_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.dtype\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_raw2 = tf.image.decode_jpeg(open('images/cnn/test_image.jpeg', 'rb').read(), channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_raw2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = transform_img_fn(['images/cnn/test_image.jpeg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imresize\n",
    "def prepare_image(image, target_width = 299, target_height = 299, max_zoom = 0.2):\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    image_ratio = width/height\n",
    "    target_image_ratio = target_width/target_height\n",
    "    crop_vertically = image_ratio<target_image_ratio\n",
    "    crop_width = width if crop_vertically else int(height*target_image_ratio)\n",
    "    crop_height = int(width/target_image_ratio) if crop_vertically else height\n",
    "  \n",
    "    #做出一個window，大小在1／1.0~1.2\n",
    "    resize_factor = np.random.rand() * max_zoom + 1.0\n",
    "    crop_width = int(crop_width / resize_factor)\n",
    "    crop_height = int(crop_height / resize_factor)\n",
    "    \n",
    "    x0 = np.random.randint(0, width - crop_width)\n",
    "    y0 = np.random.randint(0, height - crop_height)\n",
    "    x1 = x0 + crop_width\n",
    "    y1 = y0 + crop_height\n",
    "    \n",
    "    image = image[y0:y1, x0:x1]\n",
    "    \n",
    "    #翻一下\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = np.fliplr(image)\n",
    "        \n",
    "    image = imresize(image, (target_width, target_height))\n",
    "    return image.astype(np.float32)/255\n",
    "#    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_data = tf.gfile.FastGFile('images/cnn/cat.jpg', 'rb').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
